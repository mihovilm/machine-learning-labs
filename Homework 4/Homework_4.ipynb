{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Multi-class classification\n",
    "### Mihovil Mandic, Winter 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"CS74_HW4_training_set.csv\", sep=\",\")\n",
    "test_data = pd.read_csv(\"CS74_HW4_test_set.csv\", sep=\",\")\n",
    "new_test_data = test_data.copy()\n",
    "\n",
    "X_train = train_data.astype(float).iloc[:, 0:6]\n",
    "y_train = train_data.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X, y):\n",
    "    # feature extraction\n",
    "    test = SelectKBest(k='all')\n",
    "    fit = test.fit(X, y)\n",
    "\n",
    "    # summarize scores\n",
    "    np.set_printoptions(precision=3)\n",
    "    print(\"Scores\")\n",
    "    idx = 0\n",
    "    for score in fit.scores_:\n",
    "        idx += 1\n",
    "        print(\"Feature_{0}: {1} \".format(idx, score))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "Feature_1: 112.90771722985501 \n",
      "Feature_2: 88.12072461283138 \n",
      "Feature_3: 6.885545081048831 \n",
      "Feature_4: 68.09609641702006 \n",
      "Feature_5: 129.69918388243306 \n",
      "Feature_6: 86.2169350649155 \n"
     ]
    }
   ],
   "source": [
    "feature_selection(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering dropping Feature_3. Scores are based on the ANOVA F-values.\n",
    "\n",
    "Update - Dropping that feature doesn't make a significant difference, so I will preserve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning for SVM, including OVR / OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.643\n",
      "{'C': 30, 'gamma': 1e-06, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "def svm_param_tuning(X, y, k_folds):\n",
    "    Cs = [1, 10, 30, 50, 100]\n",
    "    gammas = [1e-6, 1e-5, 1e-3, 1e-1]\n",
    "    kernels = ['rbf', 'linear']\n",
    "    decisions = ['ovr', 'ovo']\n",
    "    \n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels, 'decision_function_shape'=decisions}\n",
    "    model = svm.SVC(cache_size=25000)\n",
    "    grid_search = GridSearchCV(model, param_grid, n_jobs=-1, cv=k_folds, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    print('Best accuracy: ', grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_params_\n",
    "\n",
    "#print(svm_param_tuning(X_train, y_train, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_tuning(X, y, k_folds):\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 5)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 6]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 100, num = 5)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    \n",
    "    param_grid = {'bootstrap': bootstrap,\n",
    "                  'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}    \n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=k_folds, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('Best accuracy: ', grid_search.best_score_)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "#print(random_forest_tuning(X_train, y_train, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest worked a lot better than SVM, however it underperformed Extra trees.\n",
    "Commented out SVM and RF grid search because of the runtime in case the entire notebook is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees - BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.7613333333333333\n",
      "{'bootstrap': False, 'max_depth': 52, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "def extra_trees_tuning(X, y, k_folds):\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [100, 180, 200, 250, 300, 800, 1500, 2000]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto']\n",
    "    # Maximum number of levels in tree\n",
    "    #max_depth = [1, 10, 30, 50, 70, 100]\n",
    "    max_depth = [52, 55]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 6, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    \n",
    "    param_grid = {'bootstrap': bootstrap,\n",
    "                  'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}    \n",
    "    \n",
    "    model = ExtraTreesClassifier()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=k_folds, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('Best accuracy: ', grid_search.best_score_)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "print(extra_trees_tuning(X_train, y_train, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier seemed the best with default parameters when I was testing all possible classifiers.\n",
    "Thus, I've decided to **optimize hyperparameters** for it.\n",
    "\n",
    "Those ended up being\n",
    "{'bootstrap': False, 'max_depth': 52, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
    "\n",
    "With a mean accuracy of 0.7613 and std. dev +- 0.028."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    clf = ExtraTreesClassifier(n_estimators=200,\n",
    "                          max_depth=52,\n",
    "                          max_features='auto',\n",
    "                          min_samples_split=6,\n",
    "                          min_samples_leaf=1,\n",
    "                          bootstrap=False,\n",
    "                          n_jobs=-1)\n",
    "    \n",
    "    #clf = OneVsRestClassifier(clf)\n",
    "    #clf = OneVsOneClassifier(clf)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "clf = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've commented out OVR and OVO classifiers as they worsened accuracy (in both cases, OVO did even worse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold CV accuracy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.767 0.801 0.744 0.757 0.737 0.781 0.781 0.727 0.764 0.743]\n",
      "Accuracy: 0.760 (+/- 0.044)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no feature selection or training data preprocessing, the mean accuracy is roughly **76%** after a 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.97      0.95       533\n",
      "           2       0.74      0.77      0.76       368\n",
      "           3       0.71      0.73      0.72       529\n",
      "           4       0.65      0.61      0.63       459\n",
      "           5       0.73      0.68      0.70       361\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2250\n",
      "   macro avg       0.75      0.75      0.75      2250\n",
      "weighted avg       0.76      0.76      0.76      2250\n",
      "\n",
      "Accuracy is: 0.7617777777777778\n"
     ]
    }
   ],
   "source": [
    "def per_class_CV(train_data):\n",
    "    X = train_data.columns[0:6] # features (all)\n",
    "    y = train_data.columns[6] # target (class label - last column)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data[X], train_data[y])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Accuracy is:', accuracy_score(y_test, y_pred))\n",
    "    return\n",
    "\n",
    "per_class_CV(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, test_data):\n",
    "    return clf.predict(test_data)\n",
    "\n",
    "new_test_data['Label'] = predict(clf, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - Label counts\n",
      "3    0.244444\n",
      "1    0.222222\n",
      "4    0.200000\n",
      "5    0.166667\n",
      "2    0.166667\n",
      "Name: Label, dtype: float64 \n",
      "\n",
      "Testing data - Label counts\n",
      "3    0.262037\n",
      "1    0.229630\n",
      "2    0.178704\n",
      "4    0.175926\n",
      "5    0.153704\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data - Label counts\")\n",
    "print(train_data['Label'].value_counts(normalize=True), '\\n')\n",
    "\n",
    "print(\"Testing data - Label counts\")\n",
    "print(new_test_data['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions are different, considering that there was an even number of class 5 and class 2 rows in the training data, but not in the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving into a new CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data.to_csv(\"CS74_HW4_test_set_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix - Conclusion and other classifiers I've tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = OneVsOneClassifier(RandomForestClassifier(n_estimators=1600,\n",
    "#                              max_depth = None,\n",
    "#                              max_features='auto',\n",
    "#                              min_samples_split=5,\n",
    "#                              min_samples_leaf=1,\n",
    "#                             bootstrap=True,\n",
    "#                             n_jobs=-1))\n",
    "\n",
    "# Best so far\n",
    "clf = OneVsRestClassifier(ExtraTreesClassifier(n_estimators=200,\n",
    "                          max_depth=52,\n",
    "                          max_features='auto',\n",
    "                          min_samples_split=6,\n",
    "                          min_samples_leaf=1,\n",
    "                          bootstrap=False,\n",
    "                          n_jobs=-1))\n",
    "\n",
    "#clf = ExtraTreesClassifier(n_jobs=-1)\n",
    "\n",
    "#clf = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "#clf = BaggingClassifier(KNeighborsClassifier(algorithm='kd_tree'), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "#clf = RadiusNeighborsClassifier(radius=2000000)\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=1600,\n",
    "#                                 max_depth=None,\n",
    "#                                 min_samples_split=5,\n",
    "#                                 min_samples_leaf=1,)\n",
    "\n",
    "#clf = GradientBoostingClassifier(loss='exponential', learning_rate=0.5, n_estimators=1500)\n",
    "\n",
    "# clf = GaussianProcessClassifier(multi_class=\"one_vs_rest\",\n",
    "#                                 n_jobs=-1,)\n",
    "\n",
    "#clf = Perceptron(penalty='elasticnet', alpha=1e-7, max_iter=20000, tol=1e-6)\n",
    "\n",
    "#clf = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, I've selected Extra Trees as my classifier as it performed most-consistently at 75% level accuracy with a low standard deviation. OneVsRest and OneVsOne haven't made a huge impact - except for SVM. However it significantly prolonged my runtime, so I wasn't able to run a full grid search and 10-fold CV while testing both OVR and OVO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
